{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from hazm import Normalizer, WordTokenizer, Lemmatizer, WordEmbedding\n",
    "import string \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"emails.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿ممنون آقا سامان.\\nمن پارسال اصلا آزاد شرکت نک...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿سلام آقای کریمی\\nبالاخره آزمونارشد تموم شد من...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>﻿درود بر حاج وحیدی بنده بعنوان یک دکتری تاریخ ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>﻿با سلام  و احترام\\nضمن تقدیر از مسولین محترم ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>﻿با سلام اینجانب یک دستگاه خودرو پراید 131 با ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>﻿\\nبسمه تعالی\\n\\nسازمان زیباسازی شهرداری استان...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>﻿\\n\\nبه مناسبت فرا رسیدن میلاد دخت پیامبر گرام...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>﻿\\nدرود هموطن من\\n\\n \\n\\nتست رایگان   \\n\\n    ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>﻿\\n\\n    *درج **لینک  در 8700 وبلاگ\\n    *\\n\\n...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>﻿\\nسلام به دوستان عزیز\\nشما هم میتوانید از این...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text label\n",
       "0    ﻿ممنون آقا سامان.\\nمن پارسال اصلا آزاد شرکت نک...   ham\n",
       "1    ﻿سلام آقای کریمی\\nبالاخره آزمونارشد تموم شد من...   ham\n",
       "2    ﻿درود بر حاج وحیدی بنده بعنوان یک دکتری تاریخ ...   ham\n",
       "3    ﻿با سلام  و احترام\\nضمن تقدیر از مسولین محترم ...   ham\n",
       "4    ﻿با سلام اینجانب یک دستگاه خودرو پراید 131 با ...   ham\n",
       "..                                                 ...   ...\n",
       "995  ﻿\\nبسمه تعالی\\n\\nسازمان زیباسازی شهرداری استان...  spam\n",
       "996  ﻿\\n\\nبه مناسبت فرا رسیدن میلاد دخت پیامبر گرام...  spam\n",
       "997  ﻿\\nدرود هموطن من\\n\\n \\n\\nتست رایگان   \\n\\n    ...  spam\n",
       "998  ﻿\\n\\n    *درج **لینک  در 8700 وبلاگ\\n    *\\n\\n...  spam\n",
       "999  ﻿\\nسلام به دوستان عزیز\\nشما هم میتوانید از این...  spam\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing '\\n's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the \"\\n\" characters from the text column\n",
    "df['text'] = df['text'].str.replace('\\n', ' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove punctuation from text\n",
    "def remove_punctuation(text):\n",
    "    # Define a translation table with all punctuation characters mapped to None\n",
    "    translator = str.maketrans(' ', ' ', string.punctuation)\n",
    "    # Remove punctuation using the translation table\n",
    "    return text.translate(translator)\n",
    "\n",
    "# Apply the function to the \"Content\" column\n",
    "df['text'] = df['text'].apply(remove_punctuation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove numbers from text using regular expressions\n",
    "def remove_numbers(text):\n",
    "    # Use regular expression to remove all numbers\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "df['text'] = df['text'].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "df['text'] = df['text'].apply(lambda text: normalizer.normalize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordTokenizer()\n",
    "df['Tokenized_Content'] = df['text'].apply(lambda text: tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read stop words from the text file\n",
    "with open(\"PersianStopWords.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    stop_words = set(file.read().splitlines())\n",
    "\n",
    "# Define a function to remove stop words\n",
    "def remove_stop_words(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# Apply the function to the \"Tokenized_Content\" column\n",
    "df['Tokenized_Content'] = df['Tokenized_Content'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Tokenized_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿ممنون آقا سامان من پارسال اصلا آزاد شرکت نکرد...</td>\n",
       "      <td>ham</td>\n",
       "      <td>[﻿ممنون, آقا, سامان, آزاد, شرکت, نکرده_بودم, س...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿سلام آقای کریمی بالاخره آزمونارشد تموم شد من ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>[﻿سلام, آقای, کریمی, آزمونارشد, تموم, شدم, یکم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>﻿درود بر حاج وحیدی بنده بعنوان یک دکتری تاریخ ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>[﻿درود, حاج, وحیدی, بنده, بعنوان, یک, دکتری, ت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>﻿با سلام و احترام ضمن تقدیر از مسولین محترم سا...</td>\n",
       "      <td>ham</td>\n",
       "      <td>[﻿با, سلام, احترام, ضمن, تقدیر, مسولین, محترم,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>﻿با سلام اینجانب یک دستگاه خودرو پراید با شمار...</td>\n",
       "      <td>ham</td>\n",
       "      <td>[﻿با, سلام, اینجانب, یک, دستگاه, خودرو, پراید,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>﻿ بسمه تعالی سازمان زیباسازی شهرداری استان تهر...</td>\n",
       "      <td>spam</td>\n",
       "      <td>[﻿, بسمه, تعالی, سازمان, زیباسازی, شهرداری, اس...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>﻿ به مناسبت فرا رسیدن میلاد دخت پیامبر گرامی ا...</td>\n",
       "      <td>spam</td>\n",
       "      <td>[﻿, مناسبت, فرا, رسیدن, میلاد, دخت, پیامبر, گر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>﻿ درود هموطن من تست رایگان تحویل اکانت پرداخت ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>[﻿, درود, هموطن, تست, رایگان, تحویل, اکانت, پر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>﻿ درج لینک در وبلاگ درج لینک و تبلیغات متنی شم...</td>\n",
       "      <td>spam</td>\n",
       "      <td>[﻿, درج, لینک, وبلاگ, درج, لینک, تبلیغات, متنی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>﻿ سلام به دوستان عزیز شما هم می‌توانید از اینت...</td>\n",
       "      <td>spam</td>\n",
       "      <td>[﻿, سلام, دوستان, عزیز, می‌توانید, اینترنت, ری...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text label  \\\n",
       "0    ﻿ممنون آقا سامان من پارسال اصلا آزاد شرکت نکرد...   ham   \n",
       "1    ﻿سلام آقای کریمی بالاخره آزمونارشد تموم شد من ...   ham   \n",
       "2    ﻿درود بر حاج وحیدی بنده بعنوان یک دکتری تاریخ ...   ham   \n",
       "3    ﻿با سلام و احترام ضمن تقدیر از مسولین محترم سا...   ham   \n",
       "4    ﻿با سلام اینجانب یک دستگاه خودرو پراید با شمار...   ham   \n",
       "..                                                 ...   ...   \n",
       "995  ﻿ بسمه تعالی سازمان زیباسازی شهرداری استان تهر...  spam   \n",
       "996  ﻿ به مناسبت فرا رسیدن میلاد دخت پیامبر گرامی ا...  spam   \n",
       "997  ﻿ درود هموطن من تست رایگان تحویل اکانت پرداخت ...  spam   \n",
       "998  ﻿ درج لینک در وبلاگ درج لینک و تبلیغات متنی شم...  spam   \n",
       "999  ﻿ سلام به دوستان عزیز شما هم می‌توانید از اینت...  spam   \n",
       "\n",
       "                                     Tokenized_Content  \n",
       "0    [﻿ممنون, آقا, سامان, آزاد, شرکت, نکرده_بودم, س...  \n",
       "1    [﻿سلام, آقای, کریمی, آزمونارشد, تموم, شدم, یکم...  \n",
       "2    [﻿درود, حاج, وحیدی, بنده, بعنوان, یک, دکتری, ت...  \n",
       "3    [﻿با, سلام, احترام, ضمن, تقدیر, مسولین, محترم,...  \n",
       "4    [﻿با, سلام, اینجانب, یک, دستگاه, خودرو, پراید,...  \n",
       "..                                                 ...  \n",
       "995  [﻿, بسمه, تعالی, سازمان, زیباسازی, شهرداری, اس...  \n",
       "996  [﻿, مناسبت, فرا, رسیدن, میلاد, دخت, پیامبر, گر...  \n",
       "997  [﻿, درود, هموطن, تست, رایگان, تحویل, اکانت, پر...  \n",
       "998  [﻿, درج, لینک, وبلاگ, درج, لینک, تبلیغات, متنی...  \n",
       "999  [﻿, سلام, دوستان, عزیز, می‌توانید, اینترنت, ری...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tokenized_Content'] = df['Tokenized_Content'].apply(lambda tokens: ' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordEmbedding = WordEmbedding(model_type = 'fasttext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
